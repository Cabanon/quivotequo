<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="utf8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.classless.min.css"/>
        <link rel="stylesheet" href="/bundle.css">
        
    </head>
    <body>
        <header>
            <nav>
            <ul>
                <li><h1>QuiVoteQuoi?</h1></li>
            </ul>
            <ul>
                <li><a href="/members">Membres</a></li>
            </ul>
            </nav>
        </header>
        <main>
          
<a href="/">◀️ Retourner à la recherche</a>
<h2>L’intelligence artificielle en droit pénal et son utilisation par les autorités policières et judiciaires dans les affaires pénales</h2>




<h3>🎯 Résultat</h3>
<section>

    🔎 Vote introuvable

</section>
<h3>🏷 Sujets</h3>
<ul>
    
    
        
        
            <li><a href="/subject/3">Politiques communautaires</a></li>
        
    
        
        
            <li><a href="/subject/7.40.04">Coopération judiciaire en matière pénale</a></li>
        
    
        
        
            <li><a href="/subject/7.30">Coopération policière, judiciaire et douanière en général</a></li>
        
    
        
        
            <li><a href="/subject/7.30.05">Coopération policière</a></li>
        
    
        
        
            <li><a href="/subject/3.40.06">Industries électronique, électrotechnique, TIC, robotique</a></li>
        
    
        
        
            <li><a href="/subject/7">Espace de liberté, de sécurité et de justice</a></li>
        
    
        
        
            <li><a href="/subject/3.30.06">Technologies de l&#39;information et de la communication, technologies numériques</a></li>
        
    
        
        
            <li><a href="/subject/3.40">Politique industrielle</a></li>
        
    
        
        
            <li><a href="/subject/3.30">Information et communication, généralités</a></li>
        
    
        
        
            <li><a href="/subject/7.40">Coopération judiciaire</a></li>
        
    
</ul>
<h3>📓 Amendements</h3>

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    
        <h4>📝 Amendement n°1 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      24. note que la police prédictive fait partie des applications d’IA utilisées dans le domaine répressif, mais attire l’attention sur le fait que, si elle permet d’analyser des séries de données en vue de l’identification de modèles et corrélations, elle ne peut répondre à la question de la causalité et prédire de manière fiable le comportement des personnes, et ne peut donc pas constituer à elle seule une base d’intervention; souligne que plusieurs villes des États-Unis ont cessé d’utiliser leurs systèmes de police prédictive à la suite d’audits; rappelle que, lors de la mission de la commission LIBE aux États- Unis en février 2020, les services de police de New York et de Cambridge    (Massachusetts) ont indiqué qu’ils avaient progressivement abandonné leurs programmes de police prédictive, en raison de leur manque d’efficacité, de leur effet discriminatoire et de leur échec dans la pratique, au profit de la police de proximité; observe que ce changement a entraîné une baisse du taux de criminalité; 
  

  
      <del>s’oppose </del>
  

  
      <ins>invite </ins>
  

  
      dès lors 
  

  
      <del>à ce que </del>
  

  
      les autorités répressives 
  

  
      <ins>à faire preuve de la plus grande prudence lorsqu’elles </ins>
  

  
      utilisent l’IA pour prédire le comportement de personnes ou de groupes en se fondant sur des données historiques et les comportements passés, l’appartenance à un groupe, la localisation ou toute autre caractéristique de ce type, en tentant ainsi d’identifier les personnes susceptibles de commettre une infraction;
  

  
      <ins> souligne que ces outils ne devraient être utilisés que lorsque toutes les garanties nécessaires auront été mises en place pour éliminer les préjugés existants; invite les États membres et les autorités répressives à surveiller en permanence les effets, la nécessité et les éventuelles conséquences négatives de ces outils; souligne que ces outils ne peuvent être utilisés que comme des aides et ne peuvent être le seul élément sur lequel s’appuient les services répressifs; invite toutefois la Commission et les États membres à soutenir les environnements d’essai et les projets pilotes pour permettre la poursuite du développement et l’amélioration de ces outils en vue de les rendre plus solides et précis;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135806">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°1 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      24. note que la police prédictive fait partie des applications d’IA utilisées dans le domaine répressif, mais attire l’attention sur le fait que, si elle permet d’analyser des séries de données en vue de l’identification de modèles et corrélations, elle ne peut répondre à la question de la causalité et prédire de manière fiable le comportement des personnes, et ne peut donc pas constituer à elle seule une base d’intervention; souligne que plusieurs villes des États-Unis ont cessé d’utiliser leurs systèmes de police prédictive à la suite d’audits; rappelle que, lors de la mission de la commission LIBE aux États- Unis en février 2020, les services de police de New York et de Cambridge    (Massachusetts) ont indiqué qu’ils avaient progressivement abandonné leurs programmes de police prédictive, en raison de leur manque d’efficacité, de leur effet discriminatoire et de leur échec dans la pratique, au profit de la police de proximité; observe que ce changement a entraîné une baisse du taux de criminalité; 
  

  
      <del>s’oppose </del>
  

  
      <ins>invite </ins>
  

  
      dès lors 
  

  
      <del>à ce que </del>
  

  
      les autorités répressives 
  

  
      <ins>à faire preuve de la plus grande prudence lorsqu’elles </ins>
  

  
      utilisent l’IA pour prédire le comportement de personnes ou de groupes en se fondant sur des données historiques et les comportements passés, l’appartenance à un groupe, la localisation ou toute autre caractéristique de ce type, en tentant ainsi d’identifier les personnes susceptibles de commettre une infraction;
  

  
      <ins> souligne que ces outils ne devraient être utilisés que lorsque toutes les garanties nécessaires auront été mises en place pour éliminer les préjugés existants; invite les États membres et les autorités répressives à surveiller en permanence les effets, la nécessité et les éventuelles conséquences négatives de ces outils; souligne que ces outils ne peuvent être utilisés que comme des aides et ne peuvent être le seul élément sur lequel s’appuient les services répressifs; invite toutefois la Commission et les États membres à soutenir les environnements d’essai et les projets pilotes pour permettre la poursuite du développement et l’amélioration de ces outils en vue de les rendre plus solides et précis;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135806">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°1 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      24. note que la police prédictive fait partie des applications d’IA utilisées dans le domaine répressif, mais attire l’attention sur le fait que, si elle permet d’analyser des séries de données en vue de l’identification de modèles et corrélations, elle ne peut répondre à la question de la causalité et prédire de manière fiable le comportement des personnes, et ne peut donc pas constituer à elle seule une base d’intervention; souligne que plusieurs villes des États-Unis ont cessé d’utiliser leurs systèmes de police prédictive à la suite d’audits; rappelle que, lors de la mission de la commission LIBE aux États- Unis en février 2020, les services de police de New York et de Cambridge    (Massachusetts) ont indiqué qu’ils avaient progressivement abandonné leurs programmes de police prédictive, en raison de leur manque d’efficacité, de leur effet discriminatoire et de leur échec dans la pratique, au profit de la police de proximité; observe que ce changement a entraîné une baisse du taux de criminalité; 
  

  
      <del>s’oppose </del>
  

  
      <ins>invite </ins>
  

  
      dès lors 
  

  
      <del>à ce que </del>
  

  
      les autorités répressives 
  

  
      <ins>à faire preuve de la plus grande prudence lorsqu’elles </ins>
  

  
      utilisent l’IA pour prédire le comportement de personnes ou de groupes en se fondant sur des données historiques et les comportements passés, l’appartenance à un groupe, la localisation ou toute autre caractéristique de ce type, en tentant ainsi d’identifier les personnes susceptibles de commettre une infraction;
  

  
      <ins> souligne que ces outils ne devraient être utilisés que lorsque toutes les garanties nécessaires auront été mises en place pour éliminer les préjugés existants; invite les États membres et les autorités répressives à surveiller en permanence les effets, la nécessité et les éventuelles conséquences négatives de ces outils; souligne que ces outils ne peuvent être utilisés que comme des aides et ne peuvent être le seul élément sur lequel s’appuient les services répressifs; invite toutefois la Commission et les États membres à soutenir les environnements d’essai et les projets pilotes pour permettre la poursuite du développement et l’amélioration de ces outils en vue de les rendre plus solides et précis;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135806">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°2 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      27. 
  

  
      <del>demande toutefois un moratoire sur </del>
  

  
      <ins>estime que les normes techniques pour </ins>
  

  
      le déploiement des systèmes de reconnaissance faciale 
  

  
      <del>à des fins répressives destinés à l’identification, à moins qu’ils ne soient utilisés qu’aux fins de l’identification des victimes de la criminalité, jusqu’à ce que les normes techniques puissent être considérées comme pleinement respectueuses des droits fondamentaux, </del>
  

  
      <ins>par les autorités répressives aux fins de l’identification devraient être encore améliorées pour assurer le respect des droits fondamentaux, en particulier pour veiller à ce </ins>
  

  
      que les résultats 
  

  
      <del>obtenus </del>
  

  
      ne soient ni biaisés, ni 
  

  
      <del>discriminatoires, que le cadre juridique offre des garanties strictes contre les utilisations abusives ainsi qu’un contrôle et une surveillance démocratiques rigoureux, et que la nécessité et la    proportionnalité du déploiement de ces technologies soient prouvées de manière empirique; relève que lorsque les critères susmentionnés ne sont pas remplis, les systèmes ne devraient pas être utilisés ou déployés;</del>
  

  
      <ins>discriminatoires; demande à la Commission et aux États membres de faire preuve d’une extrême prudence lorsqu’ils autorisent les services répressifs à utiliser des applications de reconnaissance faciale et d’exiger une autorisation judiciaire préalable; souligne qu’il convient de renforcer encore la    surveillance et le contrôle démocratiques afin que ces technologies ne soient utilisées que lorsque cela est nécessaire et proportionné; met en particulier l’accent sur le rôle important des systèmes de reconnaissance faciale dans l’identification des victimes;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135807">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°2 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      27. 
  

  
      <del>demande toutefois un moratoire sur </del>
  

  
      <ins>estime que les normes techniques pour </ins>
  

  
      le déploiement des systèmes de reconnaissance faciale 
  

  
      <del>à des fins répressives destinés à l’identification, à moins qu’ils ne soient utilisés qu’aux fins de l’identification des victimes de la criminalité, jusqu’à ce que les normes techniques puissent être considérées comme pleinement respectueuses des droits fondamentaux, </del>
  

  
      <ins>par les autorités répressives aux fins de l’identification devraient être encore améliorées pour assurer le respect des droits fondamentaux, en particulier pour veiller à ce </ins>
  

  
      que les résultats 
  

  
      <del>obtenus </del>
  

  
      ne soient ni biaisés, ni 
  

  
      <del>discriminatoires, que le cadre juridique offre des garanties strictes contre les utilisations abusives ainsi qu’un contrôle et une surveillance démocratiques rigoureux, et que la nécessité et la    proportionnalité du déploiement de ces technologies soient prouvées de manière empirique; relève que lorsque les critères susmentionnés ne sont pas remplis, les systèmes ne devraient pas être utilisés ou déployés;</del>
  

  
      <ins>discriminatoires; demande à la Commission et aux États membres de faire preuve d’une extrême prudence lorsqu’ils autorisent les services répressifs à utiliser des applications de reconnaissance faciale et d’exiger une autorisation judiciaire préalable; souligne qu’il convient de renforcer encore la    surveillance et le contrôle démocratiques afin que ces technologies ne soient utilisées que lorsque cela est nécessaire et proportionné; met en particulier l’accent sur le rôle important des systèmes de reconnaissance faciale dans l’identification des victimes;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135807">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°2 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      27. 
  

  
      <del>demande toutefois un moratoire sur </del>
  

  
      <ins>estime que les normes techniques pour </ins>
  

  
      le déploiement des systèmes de reconnaissance faciale 
  

  
      <del>à des fins répressives destinés à l’identification, à moins qu’ils ne soient utilisés qu’aux fins de l’identification des victimes de la criminalité, jusqu’à ce que les normes techniques puissent être considérées comme pleinement respectueuses des droits fondamentaux, </del>
  

  
      <ins>par les autorités répressives aux fins de l’identification devraient être encore améliorées pour assurer le respect des droits fondamentaux, en particulier pour veiller à ce </ins>
  

  
      que les résultats 
  

  
      <del>obtenus </del>
  

  
      ne soient ni biaisés, ni 
  

  
      <del>discriminatoires, que le cadre juridique offre des garanties strictes contre les utilisations abusives ainsi qu’un contrôle et une surveillance démocratiques rigoureux, et que la nécessité et la    proportionnalité du déploiement de ces technologies soient prouvées de manière empirique; relève que lorsque les critères susmentionnés ne sont pas remplis, les systèmes ne devraient pas être utilisés ou déployés;</del>
  

  
      <ins>discriminatoires; demande à la Commission et aux États membres de faire preuve d’une extrême prudence lorsqu’ils autorisent les services répressifs à utiliser des applications de reconnaissance faciale et d’exiger une autorisation judiciaire préalable; souligne qu’il convient de renforcer encore la    surveillance et le contrôle démocratiques afin que ces technologies ne soient utilisées que lorsque cela est nécessaire et proportionné; met en particulier l’accent sur le rôle important des systèmes de reconnaissance faciale dans l’identification des victimes;</ins>
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135807">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°3 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      31. manifeste sa vive inquiétude quant aux projets de recherche financés dans le cadre d’Horizon 2020 qui déploient l’intelligence artificielle aux frontières extérieures, tels que le projet iBorderCtrl, un «système intelligent de détection de mensonges» qui a été testé en Hongrie, en Lettonie et en Grèce, et qui établit le profil des voyageurs sur la base d’un entretien automatisé réalisé par webcam avant le voyage et d’une analyse de 38 micro-gestes fondée sur l’intelligence artificielle; invite donc la Commission à mettre en œuvre, par des moyens législatifs et non législatifs et, au besoin, par le biais de procédures d’infraction, l’interdiction 
  

  
      <del>de tout </del>
  

  
      <ins>du traitement </ins>
  

  
         
  

  
      <del>traitement </del>
  

  
      des données biométriques, y compris des images faciales, à des fins répressives conduisant à une surveillance de masse dans les espaces accessibles au 
  

  
      <del>public;</del>
  

  
      <ins>public, sauf si et dans la mesure où son utilisation est strictement nécessaire pour des objectifs très spécifiques tels qu’une recherche ciblée des victimes de la criminalité ou la prévention d’un attentat terroriste ou d’une autre menace imminente pour la vie ou l’intégrité physique d’une personne; souligne qu’une autorisation judiciaire préalable est indispensable et que le traitement de ces données doit être limité dans l’espace et dans le temps;</ins>
  

  
       invite en outre la Commission à mettre un terme au financement de la recherche ou du déploiement de données biométriques ou de programmes 
  

  
      <del>susceptibles de donner </del>
  

  
      <ins>contribuant ou donnant </ins>
  

  
      lieu à une surveillance de 
  

  
      <del>masse dans les espaces publics;</del>
  

  
      <ins>masse, qui n’est pas conforme aux conditions fixées dans le droit de l’Union et le droit national applicables;</ins>
  

  
       souligne, dans ce contexte, qu’il y a lieu d’accorder une attention particulière et d’appliquer un cadre strict à l’utilisation de drones dans les opérations de police;
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135808">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°3 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      31. manifeste sa vive inquiétude quant aux projets de recherche financés dans le cadre d’Horizon 2020 qui déploient l’intelligence artificielle aux frontières extérieures, tels que le projet iBorderCtrl, un «système intelligent de détection de mensonges» qui a été testé en Hongrie, en Lettonie et en Grèce, et qui établit le profil des voyageurs sur la base d’un entretien automatisé réalisé par webcam avant le voyage et d’une analyse de 38 micro-gestes fondée sur l’intelligence artificielle; invite donc la Commission à mettre en œuvre, par des moyens législatifs et non législatifs et, au besoin, par le biais de procédures d’infraction, l’interdiction 
  

  
      <del>de tout </del>
  

  
      <ins>du traitement </ins>
  

  
         
  

  
      <del>traitement </del>
  

  
      des données biométriques, y compris des images faciales, à des fins répressives conduisant à une surveillance de masse dans les espaces accessibles au 
  

  
      <del>public;</del>
  

  
      <ins>public, sauf si et dans la mesure où son utilisation est strictement nécessaire pour des objectifs très spécifiques tels qu’une recherche ciblée des victimes de la criminalité ou la prévention d’un attentat terroriste ou d’une autre menace imminente pour la vie ou l’intégrité physique d’une personne; souligne qu’une autorisation judiciaire préalable est indispensable et que le traitement de ces données doit être limité dans l’espace et dans le temps;</ins>
  

  
       invite en outre la Commission à mettre un terme au financement de la recherche ou du déploiement de données biométriques ou de programmes 
  

  
      <del>susceptibles de donner </del>
  

  
      <ins>contribuant ou donnant </ins>
  

  
      lieu à une surveillance de 
  

  
      <del>masse dans les espaces publics;</del>
  

  
      <ins>masse, qui n’est pas conforme aux conditions fixées dans le droit de l’Union et le droit national applicables;</ins>
  

  
       souligne, dans ce contexte, qu’il y a lieu d’accorder une attention particulière et d’appliquer un cadre strict à l’utilisation de drones dans les opérations de police;
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135808">🗳 Voir le détail du vote</a>
        
    

    
    
        <h4>📝 Amendement n°3 | 

❌️ Rejeté

</h4>
        
            

<section>

  
      31. manifeste sa vive inquiétude quant aux projets de recherche financés dans le cadre d’Horizon 2020 qui déploient l’intelligence artificielle aux frontières extérieures, tels que le projet iBorderCtrl, un «système intelligent de détection de mensonges» qui a été testé en Hongrie, en Lettonie et en Grèce, et qui établit le profil des voyageurs sur la base d’un entretien automatisé réalisé par webcam avant le voyage et d’une analyse de 38 micro-gestes fondée sur l’intelligence artificielle; invite donc la Commission à mettre en œuvre, par des moyens législatifs et non législatifs et, au besoin, par le biais de procédures d’infraction, l’interdiction 
  

  
      <del>de tout </del>
  

  
      <ins>du traitement </ins>
  

  
         
  

  
      <del>traitement </del>
  

  
      des données biométriques, y compris des images faciales, à des fins répressives conduisant à une surveillance de masse dans les espaces accessibles au 
  

  
      <del>public;</del>
  

  
      <ins>public, sauf si et dans la mesure où son utilisation est strictement nécessaire pour des objectifs très spécifiques tels qu’une recherche ciblée des victimes de la criminalité ou la prévention d’un attentat terroriste ou d’une autre menace imminente pour la vie ou l’intégrité physique d’une personne; souligne qu’une autorisation judiciaire préalable est indispensable et que le traitement de ces données doit être limité dans l’espace et dans le temps;</ins>
  

  
       invite en outre la Commission à mettre un terme au financement de la recherche ou du déploiement de données biométriques ou de programmes 
  

  
      <del>susceptibles de donner </del>
  

  
      <ins>contribuant ou donnant </ins>
  

  
      lieu à une surveillance de 
  

  
      <del>masse dans les espaces publics;</del>
  

  
      <ins>masse, qui n’est pas conforme aux conditions fixées dans le droit de l’Union et le droit national applicables;</ins>
  

  
       souligne, dans ce contexte, qu’il y a lieu d’accorder une attention particulière et d’appliquer un cadre strict à l’utilisation de drones dans les opérations de police;
  
 
</section>

        
        
            
            
                
            
            <a href="/vote/135808">🗳 Voir le détail du vote</a>
        
    

<h4>Sources</h4>
<ul>
  <li><a href="https://oeil.secure.europarl.europa.eu/oeil/popups/ficheprocedure.do?reference=2020/2016(INI)&amp;l=fr" target="_blank">ℹ️ Procédure</a></li>
  
    <li><a href="https://www.europarl.europa.eu/doceo/document/A-9-2021-0232_FR.html" target="_blank">📜 Texte et amendements</a></li>
  
  
    <li><a href="https://www.europarl.europa.eu/doceo/document/PV-9-2021-10-05-VOT_FR.html" target="_blank">🗳 Détails des votes </a></li>
  
    <li><a href="https://www.europarl.europa.eu/doceo/document/PV-9-2021-10-06-VOT_FR.html" target="_blank">🗳 Détails des votes </a></li>
  
    <li><a href="https://www.europarl.europa.eu/doceo/document/PV-9-2021-10-07-VOT_FR.html" target="_blank">🗳 Détails des votes </a></li>
  
</ul>

        </main>
    </body>
</html>